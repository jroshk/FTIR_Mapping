{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#UV treated Silk pattern decomposition\n",
    "#Instead of using full 9 peaks, this script will instead use \"Quantitative approach to study secondary structure of proteins by FT-IR spectroscopy, using a model wheat gluten system\n",
    "Author links open overlay panelMehtapFevziogluabOguz KaanOzturkbcBruce R.HamakerbcOsvaldo H.Campanellabd\" and only analyze 4 \"peaks\"\n",
    " beta-sheet (low frequency)\n",
    " random structure & alpha helix\n",
    " beta-turn\n",
    " Beta sheet (high frequency)\n",
    "\n",
    "This notebook is bsed on a previously developed tool demonstrating how to perform spectral deconvolution using the FTIR tool suite developed by KBI Biopharma. \n",
    "\n",
    "The spectral deconvolution tools utilize the scipy solvers to deconvolute second derivative or fourier self deconvolution spectra using a guassian peak model. There are three parameters per peak (mean, height and width), and thus 36 inputs are present for a 12 peak reference set. The default peak definitions `yang_h20_2015` has 14 peaks, and thus 42 input parameters are present. The parameter space is very large, and thus different gradient based solvers are likely to converge to slightly different local minima. A least squares approach using a linear loss function `rho(z) = z` was used for decomposition\n",
    "\n",
    "Modified by Jeff\n",
    "6.2.22: Need to apply FSD to spectra as I don't think this is being applied here before the least-squares fitting method\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup, Import Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np #import to take 2nd derivative as I don't think this occured, Jeff 2.28.2022 \n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "import ftir.modeling.peak_fitting as peak_fitting\n",
    "from ftir.modeling.buffer_subtraction import find_buffer_subtraction_constant, buffer_subtract\n",
    "from ftir.modeling.peak_fitting import gaussian_minimize, gaussian_differential_evolution, gaussian_least_squares\n",
    "from ftir.modeling.peak_fitting import secondary_structure, create_fit_plots, gaussian_list, sd_baseline_correction\n",
    "from ftir.modeling.peak_fitting import create_fit_singleplot #added this to avoid additional layer of subplotting of residuals\n",
    "# from ftir.modeling.peak_definitions import yang_h20_2015, dong_h2o_1990, yang_list\n",
    "from ftir.io.utils import create_df_from_single_file\n",
    "\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data file in csv format (modify for your file path/file name between the \"\" if you want to, leave blank for GUI option)\n",
    "# Takes a csv file with first column being wavenumbers, 2nd and onward are relative intensity values, no heads\n",
    "filenamevar = r\"\"\n",
    "if bool(filenamevar):\n",
    "    rawData_df = pd.read_csv(filenamevar, header=None)\n",
    "else:\n",
    "    win = tk.Tk()\n",
    "    win.wm_attributes('-topmost', 1)\n",
    "    win.withdraw() # prevents an empty tkinter window from appearing\n",
    "    filenamevar = filedialog.askopenfilename(filetypes =[('CSV Files', '*.csv')],parent=win) #, header=1,)\n",
    "    rawData_df = pd.read_csv(filenamevar, header=None)\n",
    "    #win.attributes('-topmost', True)\n",
    "    #win.update()\n",
    "    #tk.Tk().lift()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = []\n",
    "for i in range(1,rawData_df.shape[1]):\n",
    "    dims.append(f\"cols{i}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_names = list(['wavenumber'])+ dims\n",
    "type(column_names[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_sheet_df = pd.DataFrame(rawData_df.values, columns = column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of spectra: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10816/4279067625.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;31m# performing an infinite loop for the window to display\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 54\u001b[1;33m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jrosh\\anaconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# # Jeff 6.14.2022 \n",
    "# # Make a simple input for x and y dimensions of mapping\n",
    "# # Modified from https://www.geeksforgeeks.org/python-tkinter-entry-widget/\n",
    "# # Returns xvalue and yvalue globally \n",
    "# import tkinter as tk\n",
    "# root=tk.Tk()\n",
    " \n",
    "# # setting the windows size\n",
    "# root.geometry(\"450x100\")\n",
    "# root.eval('tk::PlaceWindow . center')\n",
    "# #root.wm_attributes('-topmost', 1)\n",
    "# root.lift()\n",
    "\n",
    "# # declaring numerical variables for storing x and y values\n",
    "# x_var=tk.IntVar()\n",
    "# y_var=tk.IntVar()    \n",
    "    \n",
    "# # creating a label for x using widget Label\n",
    "# x_label = tk.Label(root, text = 'Number of mapping points in x : ', font=('calibre',10, 'bold'))\n",
    "  \n",
    "# # creating a entry for input of x using widget Entry\n",
    "# x_entry = tk.Entry(root,textvariable = x_var, font=('calibre',10,'normal'))\n",
    "  \n",
    "# # creating a label for y\n",
    "# y_label = tk.Label(root, text = 'Number of mapping points in y : ', font = ('calibre',10,'bold'))\n",
    "  \n",
    "# # creating a entry for y\n",
    "# y_entry=tk.Entry(root, textvariable = y_var, font = ('calibre',10,'normal'))\n",
    "  \n",
    "# # defining a function that will get x and y values and close the window\n",
    "# def submit():\n",
    "#     global user_message_entry, num_in_x,num_in_y\n",
    "#     num_in_x=int(x_var.get())\n",
    "#     num_in_y=int(y_var.get())\n",
    "     \n",
    "#     print(\"Total number of spectra: \" + str(num_in_x*num_in_y))\n",
    "#     #root.wm_attributes('-topmost', 0)\n",
    "#     #root.withdraw()\n",
    "#     #root.update()\n",
    "#     root.destroy()\n",
    "\n",
    "# # creating a button using the widget button that will call the submit function\n",
    "# sub_btn=tk.Button(root,text = 'Submit', command=lambda: submit())\n",
    "\n",
    "# # placing the label and entry in the required position using grid method\n",
    "# x_label.grid(row=0,column=0)\n",
    "# x_entry.grid(row=0,column=1)\n",
    "# y_label.grid(row=1,column=0)\n",
    "# y_entry.grid(row=1,column=1)\n",
    "# sub_btn.grid(row=2,column=1)\n",
    "\n",
    "  \n",
    "# # performing an infinite loop for the window to display\n",
    "# root.mainloop()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline correction\n",
    "\n",
    "Rubberband baseline correction, flipping the spectra over the y-axis, and narrowing focus only on the amide I region.(Do we need to normalize to 1?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "%matplotlib inline\n",
    "\n",
    "from ftir.modeling.buffer_subtraction import find_buffer_subtraction_constant, buffer_subtract\n",
    "from ftir.modeling.peak_fitting import gaussian_minimize, gaussian_differential_evolution, gaussian_least_squares\n",
    "from ftir.modeling.peak_fitting import secondary_structure, create_fit_plots, gaussian_list, sd_baseline_correction\n",
    "from ftir.modeling.peak_definitions import yang_h20_2015, dong_h2o_1990, four_peak, five_peak \n",
    "from ftir.io.utils import create_df_from_single_file\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "from scipy.spatial import ConvexHull"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only show between 1715 and 1595\n",
    "corrected_beta_sheet = []\n",
    "for cols_ in beta_sheet_df.columns[1:]:\n",
    "    #print(str(cols_))\n",
    "    corrected_beta_sheet.append(sd_baseline_correction(beta_sheet_df, cols=[cols_], flip=False, method='rubberband', bounds=(1715, 1595)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrected_beta_sheet[2].plot.line(x='wavenumber', y=corrected_beta_sheet[2].columns[1]).invert_xaxis()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this is in peak_fitting but I'm putting it here so peak libraries and other paramters like gain can be changed\n",
    "\n",
    "reluncert = 5\n",
    "gainnum = 0.90 #gain, was originally 0.95\n",
    "\n",
    "# #from ftir.modeling.peak_definitions import hu_Kaplan_Cebe_2006_actual\n",
    "# hu_Kaplan_Cebe_2006_rounded = {\n",
    "#     'means': [1610, 1619, 1625, 1633,  1642, 1650, 1659, 1667, 1679, 1692, 1700],\n",
    "#     'uncertainties': [(1605, 1615), (1616, 1621), (1622, 1627), (1628, 1637),\n",
    "#                       (1638, 1646), (1647, 1655), (1656, 1662), (1663, 1670),\n",
    "#                       (1671, 1685), (1686, 1696), (1697, 1703)],\n",
    "#     'relative_uncertainties': [5, 2.5, 2.5, 4.5, 4, 4, 3, 3.5, 7, 5, 3],\n",
    "#     'assignments': ['(Tyr) side chains/aggregate strands', 'aggregate \\u03B2-strand/\\u03B2-sheet(weak)', \n",
    "#                     'intermolecular \\u03B2-sheet (strong)', 'intramolecular \\u03B2-sheet (strong)^b',\n",
    "#                     'random coils/extended', 'random coils', '\\u03B1-helices', 'turns',\n",
    "#                     'turns', 'turns', 'intermolecular \\u03B2_sheets (weak)']\n",
    "# }\n",
    "\n",
    "# six_peak = {\n",
    "#     'means': [1610, 1625,  1646, 1659, 1679, 1700],\n",
    "#     'uncertainties': [(1605, 1615), (1616, 1637),\n",
    "#                       (1638, 1646), (1647, 1662), (1663, 1696), (1697, 1703)],\n",
    "#     'relative_uncertainties': [5, 10.5, 4, 7.5, 16.5, 3],\n",
    "#     'assignments': ['(Tyr) side chains/aggregate strands', 'aggregate beta-strand/beta_sheet',\n",
    "#                     'random coils', '\\u03B1-helices', 'turns', 'intermolecular beta_sheets (weak)']\n",
    "# }\n",
    "\n",
    "# four_peak = {\n",
    "#     'means': [1627,  1650, 1679,1700],\n",
    "#     'uncertainties': [(1616, 1637), (1638, 1662), (1663, 1696), (1697, 1703)],\n",
    "#     #'relative_uncertainties': [10, 12, 16,3],\n",
    "#     'relative_uncertainties': [2, 2, 1,2],\n",
    "#     'assignments': ['aggregate \\u03B2-strand/\\u03B2-sheet',\n",
    "#                     'random coils + \\u03B1 helices', '\\u03B2-turns', 'intermolecular \\u03B2-sheets (weak)']\n",
    "# }\n",
    "\n",
    "# five_peak = {\n",
    "#     'means': [1610, 1627, 1650, 1679,1700],\n",
    "#     'uncertainties': [(1605,1615),(1620, 1633), (1640, 1660), (1663, 1696), (1697, 1703)],\n",
    "#     'relative_uncertainties': [5,5, 5, 5,5],\n",
    "#     # 'uncertainties': [(1605,1615),(1616, 1637), (1638, 1662), (1663, 1696), (1697, 1703)],\n",
    "#     # 'relative_uncertainties': [5,5, 5, 5,5],\n",
    "#     'assignments': ['side-chains', 'aggregate \\u03B2-strand/\\u03B2-sheet',\n",
    "#                     'random coils + \\u03B1 helices', '\\u03B2-turns', 'intermolecular \\u03B2-sheets (weak)']\n",
    "# }\n",
    "\n",
    "\n",
    "# six_peakv2 = {\n",
    "#     'means': [1610, 1627, 1646, 1659, 1679,1700],\n",
    "#     'uncertainties': [(1605,1615),(1620, 1637), (1638,1655), (1656,1662), (1663, 1696), (1697, 1703)],\n",
    "#     'relative_uncertainties': [reluncert,reluncert,reluncert,reluncert,reluncert,reluncert],\n",
    "#     # 'uncertainties': [(1605,1615),(1616, 1637), (1638, 1662), (1663, 1696), (1697, 1703)],\n",
    "#     # 'relative_uncertainties': [5,5, 5, 5,5],\n",
    "#     'assignments': ['side-chains', 'aggregate \\u03B2-strand/\\u03B2-sheet',\n",
    "#                     'random coils', '\\u03B1 helices', '\\u03B2-turns', 'intermolecular \\u03B2-sheets (weak)']\n",
    "# }\n",
    "\n",
    "\n",
    "def gaussian_least_squares_(df, col, peaks,\n",
    "                           peak_width, params=dict()): \n",
    "# peak width taken from: \n",
    "# \"Quantitative approach to study secondary structure of proteins by FT-IR spectroscopy, using a model wheat gluten system\"\n",
    "\n",
    "    def fun(p, x, y):\n",
    "        \"\"\" Minimizing across parameter space p, for a given range, x\"\"\"\n",
    "        return gaussian_sum(x, *p) - y\n",
    "\n",
    "    data = np.array(pd.concat([df.iloc[:,0], df[col]], axis=1))\n",
    "    heights = guess_heights_(df, col, peaks['means'], gain=gainnum)\n",
    "    width = peak_width\n",
    "    lb = list()\n",
    "    ub = list()\n",
    "    guess = list()\n",
    "\n",
    "    # Make 1-D array for optimization func definition above\n",
    "    for mean, bound, height in zip(peaks['means'], peaks['uncertainties'],\n",
    "                                   heights):\n",
    "        lb.extend([0, bound[0], 0])\n",
    "        ubh = np.inf if height <= 0 else height\n",
    "        ub.extend([ubh, bound[1], peak_width*1])\n",
    "        guess.extend([height*0.95, mean, peak_width])\n",
    "\n",
    "    args = [fun, np.array(guess)]\n",
    "    params['args'] = (data[:, 0], data[:, 1])\n",
    "    params['bounds'] = (np.array(lb), np.array(ub))\n",
    "    res = optimize.least_squares(*args, **params)\n",
    "\n",
    "    areas = list()\n",
    "    for i in range(0, len(res.x), 3):\n",
    "        height = res.x[i]\n",
    "        width = res.x[i+2]\n",
    "        area = gaussian_integral(height, width)\n",
    "        areas.append(area)\n",
    "    return areas, res\n",
    "\n",
    "def guess_heights_(df, col, center_list, gain=0.90):\n",
    "    \"\"\" Determines guesses for the heights based on measured data.\n",
    "\n",
    "    Function creates an integer mapping to the measured frequencies, and then\n",
    "    creates an initial peak height guess of gain*actual height at x=freq*. A\n",
    "    Default of 0.95 seems to work best for most spectra, but can be change to\n",
    "    improve convergence.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : Dataframe\n",
    "        Dataframe containing the measured absorbance data\n",
    "\n",
    "    col : string or integer\n",
    "        Column index for the absorbance data being fit. Accepts either index\n",
    "        or string convention.\n",
    "\n",
    "    center_list : iterable of integers\n",
    "        An iterable of integer peak positions used to find the experiment\n",
    "        absorbance at a given wavenumber. I.e, the heights are returned at the\n",
    "        center values in this iterable\n",
    "\n",
    "    gain : number (optional)\n",
    "        Fraction of the measured absorbance value to use determine the initial\n",
    "        guess for the peak height. The value Default value is 0.95, and thus\n",
    "        by default, all initial peak guesses are 95% of the peak max.\n",
    "\n",
    "    \"\"\"\n",
    "    heights = []\n",
    "    freq_map = {}\n",
    "    for i in df.iloc[:,0]:\n",
    "        j = math.floor(i)\n",
    "        freq_map[j] = float(df[col].get(df.iloc[:,0] == i))\n",
    "    print(freq_map)\n",
    "    # pdb.set_trace()\n",
    "    for i in center_list:\n",
    "        height = freq_map[i]\n",
    "        heights.append(gain*height)\n",
    "    return heights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting spectra and their invidual fits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of spectra: 0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10816/113723206.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;31m# performing an infinite loop for the window to display\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mroot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\jrosh\\anaconda3\\lib\\tkinter\\__init__.py\u001b[0m in \u001b[0;36mmainloop\u001b[1;34m(self, n)\u001b[0m\n\u001b[0;32m   1427\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1428\u001b[0m         \u001b[1;34m\"\"\"Call the mainloop of Tk.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1429\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmainloop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1431\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mquit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Jeff 6.14.2022 \n",
    "# Make a simple input for x and y dimensions of mapping\n",
    "# Modified from https://www.geeksforgeeks.org/python-tkinter-entry-widget/\n",
    "# Returns xvalue and yvalue globally\n",
    "\n",
    "import tkinter as tk\n",
    "  \n",
    "root=tk.Tk()\n",
    " \n",
    "# setting the windows size\n",
    "root.geometry(\"450x100\")\n",
    "root.eval('tk::PlaceWindow . center')\n",
    "#root.lift()\n",
    "root.attributes('-topmost', 1)\n",
    "#root.lift()\n",
    "\n",
    "# declaring numerical variables for storing x and y values\n",
    "x_var=tk.IntVar()\n",
    "y_var=tk.IntVar()\n",
    "   \n",
    "# defining a function that will get x and y values and close the window\n",
    "def submit():\n",
    "    global user_message_entry, num_in_x,num_in_y\n",
    "    num_in_x=int(x_var.get())\n",
    "    num_in_y=int(y_var.get())\n",
    "     \n",
    "    print(\"Total number of spectra: \" + str(num_in_x*num_in_y))\n",
    "    root.attributes('-topmost', 0)\n",
    "    root.destroy()\n",
    "    \n",
    "    \n",
    "# creating a label for x using widget Label\n",
    "x_label = tk.Label(root, text = 'Number of mapping points in x : ', font=('calibre',10, 'bold'))\n",
    "  \n",
    "# creating a entry for input of x using widget Entry\n",
    "x_entry = tk.Entry(root,textvariable = x_var, font=('calibre',10,'normal'))\n",
    "  \n",
    "# creating a label for y\n",
    "y_label = tk.Label(root, text = 'Number of mapping points in y : ', font = ('calibre',10,'bold'))\n",
    "  \n",
    "# creating a entry for y\n",
    "y_entry=tk.Entry(root, textvariable = y_var, font = ('calibre',10,'normal'))\n",
    "  \n",
    "# creating a button using the widget button that will call the submit function\n",
    "sub_btn=tk.Button(root,text = 'Submit', command=lambda: submit())\n",
    "  \n",
    "# placing the label and entry in the required position using grid method\n",
    "x_label.grid(row=0,column=0)\n",
    "x_entry.grid(row=0,column=1)\n",
    "y_label.grid(row=1,column=0)\n",
    "y_entry.grid(row=1,column=1)\n",
    "sub_btn.grid(row=2,column=1)\n",
    "  \n",
    "# performing an infinite loop for the window to display\n",
    "root.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6/10/2022: attempt to use non-flattened indices so that I can more easily think about the math for propper placement of \"pixels\"; from above, the plots start at top left, but\n",
    "# should actually start at bottom left. Need to confirm if the grid is started from another corner whether the FT-IR starts measuring from another corner, and then possibly put another gui to allow \n",
    "# users to select which corner data collection starts in\n",
    "pw = 30 #peak width 30cm^-1 from \"Quantitative approach to study secondary structure of proteins by FT-IR spectroscopy, using a model wheat gluten system\"\n",
    "peakfitlibname = 'four_peak'\n",
    "peaksfittinglib = four_peak \n",
    "\n",
    "from matplotlib.offsetbox import AnchoredText\n",
    "\n",
    "fig, axs = plt.subplots(num_in_y,num_in_x, figsize=(num_in_x*5,num_in_y*5),dpi=200)\n",
    "titletext  = ('Peak Means:' + str(peaksfittinglib['means']) +\"\\n\" + 'Peak Relatively Uncertainties: ' + str(peaksfittinglib['relative_uncertainties']) + \n",
    "    \"\\n\" + 'Gain: ' + str(gainnum) + ' Peak Width: ' + str(pw))\n",
    "fig.suptitle(titletext, fontsize=16,y=1.05, va='top')\n",
    "fig.subplots_adjust(hspace=.2, wspace=.2)\n",
    "\n",
    "structs =[]\n",
    "gaussian_data = []\n",
    "\n",
    "for j in range(0,num_in_y):\n",
    "    for i in range(0,num_in_x):     \n",
    "\n",
    "        indexnum=(num_in_x)*(num_in_y-(j+1))+i #this should convert current index to the correct index from the original \"linear\" dataset since the data point table doesn't have any location information\n",
    "        # need to confirm that if data collection starts in another corner other than lower left (upper right, lower right, etc.), that this doesn't require a different re-indexing operation\n",
    "      \n",
    "        sample = corrected_beta_sheet[(num_in_x)*(num_in_y-1-j)+i].columns[1]\n",
    "        area, res = gaussian_least_squares(corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i], \n",
    "                                        corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i].columns[1], peak_width=pw, \n",
    "                                        peaks=peaksfittinglib, params={'loss':'linear'}) \n",
    "        structs.append(secondary_structure(area, peaksfittinglib))\n",
    "        gaussian_list_data = gaussian_list(corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i]['wavenumber'], *res.x)\n",
    "        gaussian_data.append(gaussian_list_data)\n",
    "        \n",
    "        #does this math work for crawling through the numbers? maybe this is where I need to apply the logic and put the right data in the right place?\n",
    "        xdata = corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i].iloc[:,0]\n",
    "        y_fit = sum(gaussian_list_data)\n",
    "\n",
    "        # index is a bit whack here, need to start from bottom left and starts from top left      \n",
    "        # need to modify for running a series of data not from mapping, or running a line (in which case one of the two dimensions are ==1)\n",
    "        if (num_in_y == 1) or (num_in_x == 1):\n",
    "            axs[i].plot(xdata, corrected_beta_sheet[i][sample],label='Baseline Corrected') #Jeff changed this to 'Baseline Corrected' from '$2^{nd}$ derivative' on 3.23.2022\n",
    "            axs[i].plot(xdata, y_fit, label='Model fit',ls='-.',linewidth=1) \n",
    "            # calculate RSS for each spectrum\n",
    "            resid = corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i][sample] - y_fit\n",
    "            # sum of square residuals - want to minimize this, might need to run some algorithm to do this\n",
    "            rss = sum(resid*resid)\n",
    "\n",
    "            # Jeff 5.31.22: Label each of the gaussian curves with the correct type of peak\n",
    "            for k in range(len(gaussian_list_data)):\n",
    "                axs[i].plot(xdata, gaussian_list_data[len(peaksfittinglib['means'])-1-k], ls='--', \n",
    "                label=str(peaksfittinglib['assignments'][len(peaksfittinglib['means'])-1-k])) #label=str(structs[j][1])) #label='')\n",
    "            axs[i].invert_xaxis()\n",
    "            \n",
    "            legend1 = axs[i].legend(loc=\"upper left\",fontsize='xx-small')\n",
    "            rssTitle = \"RSS: \"+ str(\"{:.1e}\".format(rss))\n",
    "            rssText = AnchoredText(rssTitle, loc='upper right', prop=dict(size=6), frameon=True)           \n",
    "            ratioText = '\\u03B2-Sheet:'+ str(\"{:.0%}\".format(structs[num_in_x*j+i]['aggregate \\u03B2-strand/\\u03B2-sheet'] +\n",
    "                structs[num_in_x*j+i]['intermolecular \\u03B2-sheets (weak)']))\n",
    "            axs[i].add_artist(rssText)\n",
    "            aRatioText = AnchoredText(ratioText, loc='upper right', prop=dict(size=6), frameon=True, bbox_to_anchor=(1., 0.85),\n",
    "                            bbox_transform=axs[i].transAxes)\n",
    "            axs[i].add_artist(aRatioText)\n",
    "            strindexnum= str(indexnum)\n",
    "            numberinlist = AnchoredText(strindexnum, loc='upper right', prop=dict(size=6), frameon=True,bbox_to_anchor=(1., 0.7),bbox_transform=axs[i].transAxes)\n",
    "            axs[i].add_artist(numberinlist)        \n",
    "        else:\n",
    "            axs[j,i].plot(xdata, corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i][sample],label='Baseline Corrected') #Jeff changed this to 'Baseline Corrected' from '$2^{nd}$ derivative' on 3.23.2022\n",
    "            axs[j,i].plot(xdata, y_fit, label='Model fit',ls='-.',linewidth=1) \n",
    "            # calculate RSS for each spectrum\n",
    "            resid = corrected_beta_sheet[(num_in_x)*(num_in_y-(j+1))+i][sample] - y_fit\n",
    "            # sum of square residuals - want to minimize this, might need to run some algorithm to do this\n",
    "            rss = sum(resid*resid)\n",
    "\n",
    "            # Jeff 5.31.22: Label each of the gaussian curves with the correct type of peak\n",
    "            for k in range(len(gaussian_list_data)):\n",
    "                axs[j,i].plot(xdata, gaussian_list_data[len(peaksfittinglib['means'])-1-k], ls='--', \n",
    "                label=str(peaksfittinglib['assignments'][len(peaksfittinglib['means'])-1-k])) #label=str(structs[j][1])) #label='')\n",
    "            axs[j,i].invert_xaxis()\n",
    "            \n",
    "            legend1 = axs[j,i].legend(loc=\"upper left\",fontsize='xx-small')\n",
    "            rssTitle = \"RSS: \"+ str(\"{:.1e}\".format(rss))\n",
    "            rssText = AnchoredText(rssTitle, loc='upper right', prop=dict(size=6), frameon=True)           \n",
    "            ratioText = '\\u03B2-Sheet:'+ str(\"{:.0%}\".format(structs[num_in_x*j+i]['aggregate \\u03B2-strand/\\u03B2-sheet'] +\n",
    "                structs[num_in_x*j+i]['intermolecular \\u03B2-sheets (weak)']))\n",
    "            axs[j,i].add_artist(rssText)\n",
    "            aRatioText = AnchoredText(ratioText, loc='upper right', prop=dict(size=6), frameon=True, bbox_to_anchor=(1., 0.85),\n",
    "                            bbox_transform=axs[j,i].transAxes)\n",
    "            axs[j,i].add_artist(aRatioText)\n",
    "            strindexnum= str(indexnum)\n",
    "            numberinlist = AnchoredText(strindexnum, loc='upper right', prop=dict(size=6), frameon=True,bbox_to_anchor=(1., 0.7),bbox_transform=axs[j,i].transAxes)\n",
    "            axs[j,i].add_artist(numberinlist)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare % of beta sheet via Seaborn Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_beta_percent = []\n",
    "for i in range(0,len(structs)):\n",
    "    total_beta_percent.append(structs[i]['aggregate \\u03B2-strand/\\u03B2-sheet'] + structs[i]['intermolecular \\u03B2-sheets (weak)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plot just in case it's useful\n",
    "plt.plot(total_beta_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap via seaborn:\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (num_in_x,num_in_y),dpi=200)\n",
    "\n",
    "#Split up points into x by y grid\n",
    "break_total_beta_percent = np.array_split(np.array(total_beta_percent),num_in_y)\n",
    "\n",
    "hmtitletext  = ('\\u03B2-sheet content' + \"\\n\")\n",
    "ax_example = sns.heatmap(break_total_beta_percent[0:(num_in_x)], cmap=\"Reds\",vmin=.1, vmax=0.3, linewidths=.05)\n",
    "plt.suptitle(hmtitletext , fontsize=16)\n",
    "fig.subplots_adjust(hspace=.2, wspace=.2)\n",
    "# ax_example.invert_yaxis()\n",
    "cbar = ax_example.collections[0].colorbar\n",
    "cbar.set_ticks([0.1,0.2,0.3])\n",
    "cbar.set_ticklabels(['10%', '20%', '30%'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D plot just in case it's useful\n",
    "plt.plot(total_beta_percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#heatmap via seaborn:\n",
    "import seaborn as sns\n",
    "plt.figure(figsize = (num_in_x,num_in_y),dpi=200)\n",
    "\n",
    "#Split up points into x by y grid\n",
    "break_total_beta_percent = np.array_split(np.array(total_beta_percent),num_in_y)\n",
    "\n",
    "hmtitletext  = ('\\u03B1-helices content' + \"\\n\")\n",
    "ax_example = sns.heatmap(break_total_beta_percent[0:(num_in_x)], cmap=\"Reds\",vmin=.1, vmax=0.3, linewidths=.05)\n",
    "plt.suptitle(hmtitletext , fontsize=16)\n",
    "fig.subplots_adjust(hspace=.2, wspace=.2)\n",
    "# ax_example.invert_yaxis()\n",
    "cbar = ax_example.collections[0].colorbar\n",
    "cbar.set_ticks([0.1,0.2,0.3])\n",
    "cbar.set_ticklabels(['10%', '20%', '30%'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a8ea5ae0aab33bbee0ebb06e8cdde650700993b43495131d0ae48b12915ec01"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
